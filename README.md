# My-Data-science-Assignments-
This repository is exclusively for my excelr assignments on different machine learning techniques in domain of Data Science
This repository contains a collection of hands-on assignments completed as part of my learning journey in statistics, machine learning, and data science. Each notebook covers foundational and advanced concepts, providing practical implementations using real or simulated datasets. The topics range from statistical analysis to supervised and unsupervised learning, dimensionality reduction, and time series forecasting.

COVERED TOPICS:

1. BASICS OF STATS-1: Performed descriptive analytics and comprehensive data preprocessing on the Sales & Discounts dataset, including statistical analysis, visualizations, standardization, and one-hot encoding to prepare the data for advanced modeling.

2. BASICS OF STATS-2:Constructed 99% confidence intervals for the mean durability of print-heads using both sample and known population standard deviations, applying t-distribution and z-distribution to support quality control decisions under destructive testing constraints.

3. BASICS OF PYTHON: Introduction to Python programming for data analysis and data science.

4. CHI-SQUARE TESTING: Determined whether there is significant association between purchased device type and customer satisfaction level by applying chi-square test.

5. HYPOTHESIS TESTING: Performed hypothesis testing to assess if the actual weekly operating costs at Bombay Hospitality Ltd. significantly exceed the projected cost model.

6. EXPLORATORY DATA ANLYSIS(EDA) 1: Conducted an in-depth exploratory data analysis on the Cardiotocographic dataset using statistical summaries and visualizations to uncover patterns in fetal heart rate indicators and provide actionable insights for further medical data interpretation.

7. MULTI LINEAR REGRESSION: Performed a multi-linear regression analysis to predict the price of Toyota corolla based on the given attributes.

8. LOGISTIC REGRESSION: Predicted survival probability on titanic dataset by using logistic regression technique.

9. CLUSTERING: Performed customer segmentation for East-West Airlines using clustering techniques to uncover patterns in flying behavior, reward usage, and credit card adoption.

10. PRINCIPAL COMPONENT ANALYSIS(PCA): Performed EDA, PCA, and clustering on the Wine dataset to uncover underlying patterns, reduce dimensionality, and compare clustering performance between original and PCA-transformed features.

11. ASSOCIATION RULES: Conducted market basket analysis on the Online Retail dataset using the Apriori algorithm and Eclat algorithm to discover and interpret meaningful product associations and customer purchasing patterns through rule mining techniques.

12. RECOMMENDATION SYSTEMS: Developed a collabarative and content-based recommendation system using cosine similarity on the Anime dataset to suggest similar titles based on features like genres and user ratings.

13. EXPLORATORY DATA ANLYSIS(EDA)-2: Executed comprehensive data preprocessing, feature engineering, and feature selection on the Adult dataset, including scaling, encoding, outlier detection with Isolation Forest, and relationship analysis using PPS to enhance predictive modeling for income classification.

14. DECISION TREES: Applied Decision Tree Classification on the Heart Disease dataset.

15. RANDOM FORESTS: Implemented Random Forest, Bagging, and Boosting models on the Glass dataset with thorough EDA, preprocessing, and performance evaluation to classify glass types and compare ensemble techniques.

16. LIGHTGBM & XTREMEGBM: Implemented LightGBM & XGBoost algorithms on Titanic(Train) dataset and compared differnt models performances and evaluated the performances on the Titanic(Test) dataset.

17. K-NEAREST NEIGHBOURS (KNN): Implemented and evaluated the K-Nearest Neighbours algorithm on the Zoo dataset to classify animal types.

18. SUPPORT VECTOR MACHINE (SVM): Implemented and optimized Support Vector Machine (SVM) models on the Mushroom dataset to classify edible vs. poisonous mushrooms by including EDA, preprocessing, kernel comparisons, and performance evaluation 

19. NEURAL NETWORKS: Built and tuned an Artificial Neural Network on the Alphabets dataset to classify alphabet categories by applying data preprocessing, hyperparameter optimization, and performance evaluation using key classification metrics.

20. NAIVE BAYES & NLP: Developed a Naive Bayes text classification model and performed sentiment analysis on the blogs dataset to accurately categorize blog posts and interpret their underlying sentiments across categories.

21. TIME SERIES ANALYSIS: Applied ARIMA and Exponential Smoothing techniques on the exchange_rate dataset to forecast USD to AUD exchange rates, including model tuning, diagnostics, and performance comparison using error metrics.

Each topic includes clean, well-commented code along with interpretations and insights. Feel free to explore the notebooks to understand how different algorithms and methods are applied in practice.


